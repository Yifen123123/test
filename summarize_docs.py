# -*- coding: utf-8 -*-
"""
summarize_docs.py
å°‡ parsed/<category>.jsonl çš„ subject/body/meta é¤µçµ¦ LLM åšçµæ§‹åŒ–æ‘˜è¦ï¼ˆæŠ½å–äººåã€èº«åˆ†è­‰ã€ä¿å–®ç¨®é¡ã€ä¿å–®è™Ÿç¢¼ç­‰ï¼‰ã€‚
æ”¯æ´ openai é¢¨æ ¼èˆ‡æœ¬åœ° ollama å…©ç¨®å¾Œç«¯ï¼Œä¸¦åŠ å…¥æ­£å‰‡é©—è­‰èˆ‡å¾Œè™•ç†ã€‚

ç”¨æ³•ï¼š
  python summarize_docs.py --input-dir parsed --output-dir summaries --backend ollama --model qwen2.5:7b-instruct
  æˆ–
  OPENAI_API_KEY=xxx python summarize_docs.py --backend openai --model gpt-4o-mini
"""

import argparse
import json
import os
import re
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple

# ----------------------------
# 1) å¾Œç«¯è¨­å®šï¼ˆé¸æ“‡ openai æˆ– ollamaï¼‰
# ----------------------------
BACKEND_CONFIG = {
    "backend": "ollama",            # "openai" æˆ– "ollama"
    "model": "qwen2.5:7b-instruct", # ä¾‹å¦‚ï¼šollama æ¨¡å‹æ¨™ç±¤ï¼›æˆ– openai çš„å‹è™Ÿ
    "temperature": 0.0,
}

# ----------------------------
# 2) æ­£å‰‡è¦å‰‡ï¼ˆå°ç£èº«åˆ†è­‰ã€ä¿å–®è™Ÿç­‰ï¼‰
# ----------------------------
TW_ID_RE  = re.compile(r"\b[A-Z][0-9]{9}\b")             # å°ç£èº«åˆ†è­‰ï¼ˆç°¡å–®ç‰ˆï¼‰
POLICY_RE = re.compile(r"\b[A-Z0-9]{8,20}\b", re.IGNORECASE)  # ä¿å–®è™Ÿï¼ˆå¸¸è¦‹è‹±æ•¸ 8-20 ä½ï¼‰
# ä¸­æ–‡å§“åï¼ˆå•Ÿç™¼å¼ï¼‰ï¼š2~4 å€‹æ¼¢å­—ï¼ˆå«å¸¸è¦‹ä¸­é»ï¼‰ï¼Œåƒ…ä½œå€™é¸ï¼Œæœ€å¾Œç”¨ LLM çµæœäº¤å‰é©—è­‰
CNAME_RE  = re.compile(r"[\u4e00-\u9fa5Â·]{2,4}")

# ----------------------------
# 3) LLM æç¤ºè©ï¼ˆæŒ‡ç¤ºè¼¸å‡º JSONï¼‰
# ----------------------------
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€å€‹åš´æ ¼çš„è³‡è¨ŠæŠ½å–å™¨ã€‚ä½ åªè¼¸å‡º JSONï¼Œçµ•ä¸å¤šèªªä¸€å¥è©±ã€‚"""

# é‡å°ã€Œä¿å–®æŸ¥è©¢ã€ä»¥åŠä¸€èˆ¬å…¬æ–‡ï¼Œçµ¦ä¸€å€‹çµ±ä¸€ schemaï¼ˆå¤šé¡åˆ¥å¯å…±ç”¨ï¼Œç¼ºçš„å°± nullï¼‰
USER_PROMPT_TEMPLATE = """è«‹æ ¹æ“šä»¥ä¸‹å…¬æ–‡å…§å®¹ï¼Œç”¢ç”Ÿçµæ§‹åŒ–æ‘˜è¦ï¼ˆJSON æ ¼å¼ã€UTF-8ã€strict JSONï¼‰ã€‚

ã€ä»»å‹™è¦æ±‚ã€‘
1. ç›®çš„ï¼šèƒå–é—œéµæ¬„ä½ï¼Œè‹¥æ²’æœ‰å°±å¡« nullã€‚
2. åƒ…è¼¸å‡º JSONï¼Œä¸è¦æ–‡å­—è§£é‡‹ã€‚
3. æ¬„ä½èªªæ˜ï¼š
   - category: åŸå§‹é¡åˆ¥ï¼ˆå¦‚ï¼šä¿å–®æŸ¥è©¢/é€šçŸ¥å‡½/æ‰£æŠ¼å‘½ä»¤â€¦ï¼‰
   - title: 10~40 å­—å…§ä¸­æ–‡æ‘˜è¦æ¨™é¡Œï¼ˆè‹¥ç„¡æ˜ç¢ºä¸»æ—¨ï¼Œä¾å…§å®¹æ“¬å®šï¼‰
   - summary: 100~200 å­—å…§è¦é»æ‘˜è¦ï¼ˆäº‹ä»¶/ä¸»é«”/å‹•ä½œ/æ™‚é–“/è¦æ±‚ï¼‰
   - persons: æ¶‰åŠä¹‹äººååˆ—è¡¨ï¼ˆä¸­æ–‡åç‚ºä¸»ï¼‰
   - ids: å¯èƒ½çš„èº«åˆ†è­‰å­—è™Ÿåˆ—è¡¨ï¼ˆæ ¼å¼æª¢æ ¸ï¼š1 è‹±æ–‡ + 9 æ•¸å­—ï¼‰
   - policy_type: ä¿å–®ç¨®é¡ï¼ˆå¦‚ï¼šå£½éšª/æ„å¤–éšª/é†«ç™‚éšª/ä¸æ˜ â†’ nullï¼‰
   - policy_numbers: ä¿å–®æˆ–å¥‘ç´„ç·¨è™Ÿåˆ—è¡¨ï¼ˆè‹±æ•¸ 8â€“20ï¼‰
   - actions: æœ¬æ–‡æ¶‰åŠä¹‹å‹•ä½œ/è¦æ±‚ï¼ˆä¾‹å¦‚ï¼šæŸ¥è©¢ã€æ’¤éŠ·ã€æ‰£æŠ¼ã€é€šçŸ¥ã€è£œä»¶ï¼‰
   - date_mentions: æ–‡ä¸­é‡è¦æ—¥æœŸï¼ˆyyyy-mm-dd æˆ–æ°‘åœ‹ç´€å¹´åŸæ¨£ï¼Œä¸å¼·åˆ¶è½‰æ›ï¼‰
   - parties: æ¶‰åŠæ©Ÿé—œ/å…¬å¸/å–®ä½ååˆ—è¡¨
   - extra: å…¶ä»–é—œéµæ¬„ä½ï¼ˆå­—å…¸ï¼‰ï¼Œå¦‚æ¡ˆä»¶è™Ÿã€æ³•é™¢å­—è™Ÿã€é‡‘é¡ã€åœ°å€ã€é›»è©±ç­‰

ã€è¼¸å‡º JSON ç¯„ä¾‹ã€‘
{{
  "category": "{category}",
  "title": "â€¦",
  "summary": "â€¦",
  "persons": ["â€¦", "â€¦"],
  "ids": ["â€¦"],
  "policy_type": "å£½éšª",
  "policy_numbers": ["â€¦"],
  "actions": ["æŸ¥è©¢"],
  "date_mentions": ["æ°‘åœ‹114å¹´01æœˆ01æ—¥", "2025-08-15"],
  "parties": ["è‡ºç£è‡ºåŒ—åœ°æ–¹æ³•é™¢", "å…¨çƒäººå£½"],
  "extra": {{"doc_no": "åŒ—é™¢åŸ·æ™ºå­—ç¬¬123è™Ÿ"}}
}}

ã€æ–‡æœ¬ã€‘
<subject>
{subject}
</subject>

<body>
{body}
</body>
"""

# ----------------------------
# 4) ç°¡å–®çš„å¾Œè™•ç†èˆ‡é©—è­‰
# ----------------------------
def _unique_keep(seq: List[str]) -> List[str]:
    seen = set()
    out = []
    for s in seq:
        if s is None:
            continue
        s2 = str(s).strip()
        if not s2 or s2 in seen:
            continue
        seen.add(s2)
        out.append(s2)
    return out

def validate_and_enhance(record: Dict[str, Any], category: str, subject: str, body: str) -> Dict[str, Any]:
    """å° LLM çµæœåšæ­£å‰‡æ ¡é©—èˆ‡å¢è£œï¼ˆåƒ…ä¿å®ˆåœ°ä¿®æ­£/è£œé½Šï¼Œä¸åšéåº¦æ”¹å¯«ï¼‰"""
    out = dict(record)

    # personsï¼šè‹¥ç„¡ï¼Œå¾æ–‡æœ¬ç”¨å•Ÿç™¼å¼è£œå€™é¸ï¼ˆå¯èƒ½æœƒæœ‰å…¬å‹™ç”¨è©èª¤æ“Šï¼Œåƒ…ä½œè¼”åŠ©ï¼‰
    persons = out.get("persons") or []
    if isinstance(persons, list) is False:
        persons = []
    # å¾ subject/body æŠ“ä¸­æ–‡å§“åå€™é¸
    candidates = CNAME_RE.findall(subject + "\n" + body)
    # æ’é™¤å¸¸è¦‹å…¬æ–‡å­—çœ¼ï¼ˆéå¸¸ç²—ç³™ï¼Œå¯å†æ“´å…… stoplistï¼‰
    stop = {"é™„ä»¶", "èªªæ˜", "ä¸»æ—¨", "é€šçŸ¥", "æœ¬é™¢", "æœ¬å±€", "æœ¬å…¬å¸", "æ‰¿è¾¦", "æ‰¿è¾¦äºº", "å¾©æ–‡"}
    candidates = [c for c in candidates if c not in stop]
    persons = _unique_keep(list(persons) + candidates[:5])  # ä¸è¦å¤ªå¤šï¼Œæœ€å¤šè£œ 5 å€‹
    out["persons"] = persons

    # idsï¼šæ­£å‰‡æ ¡é©—å°ç£èº«åˆ†è­‰
    ids = out.get("ids") or []
    if isinstance(ids, list) is False:
        ids = []
    regex_ids = TW_ID_RE.findall(subject + "\n" + body)
    # äº¤é›†å„ªå…ˆï¼šä¿ç•™ LLM æœ‰çš„ + æ­£å‰‡è£œçš„
    ids = _unique_keep(list(ids) + regex_ids)
    out["ids"] = ids

    # policy_numbersï¼šæ­£å‰‡è£œ
    pols = out.get("policy_numbers") or []
    if isinstance(pols, list) is False:
        pols = []
    regex_pols = POLICY_RE.findall(subject + "\n" + body)
    # æ’é™¤æ˜é¡¯ä¸åƒä¿å–®çš„çŸ­ç¢¼ï¼ˆä¾‹å¦‚ "DOCNO2025" ä»å¯èƒ½æ˜¯æ–‡è™Ÿï¼Œçœ‹æƒ…æ³ä¿ç•™ï¼‰
    pols = _unique_keep(list(pols) + regex_pols)
    out["policy_numbers"] = pols

    # policy_typeï¼šè‹¥ç©ºï¼Œå¯ä»¥ç”¨é—œéµè©å•Ÿç™¼å¼è£œï¼ˆéå¸¸ç°¡å–®ï¼Œå¯ä¾ä½ è³‡æ–™å†æ“´å……ï¼‰
    if not out.get("policy_type"):
        s = subject + "\n" + body
        if "å£½éšª" in s:
            out["policy_type"] = "å£½éšª"
        elif "æ„å¤–éšª" in s:
            out["policy_type"] = "æ„å¤–éšª"
        elif "é†«ç™‚éšª" in s or "é†«ç™‚ä¿éšª" in s:
            out["policy_type"] = "é†«ç™‚éšª"
        elif "å‚·å®³éšª" in s:
            out["policy_type"] = "å‚·å®³éšª"
        elif "ç«éšª" in s:
            out["policy_type"] = "ç«éšª"
        else:
            out["policy_type"] = None

    # actionsï¼šè‹¥ç©ºï¼Œé—œéµè©è£œ
    if not out.get("actions"):
        actions = []
        s = subject + "\n" + body
        for k in ["æŸ¥è©¢", "æ’¤éŠ·", "æ‰£æŠ¼", "é€šçŸ¥", "è£œä»¶", "æ›´æ­£", "å‡½è¦†", "æª¢é€", "è½‰çŸ¥", "æ‹è³£", "åŸ·è¡Œ", "èª¿æŸ¥"]:
            if k in s:
                actions.append(k)
        out["actions"] = _unique_keep(actions) or None

    # extraï¼šç¢ºä¿æ˜¯ dict
    if not isinstance(out.get("extra"), dict):
        out["extra"] = {}

    # category å›å¯«ï¼ˆé¿å… LLM æ”¹å‹•ï¼‰
    out["category"] = category

    return out

# ----------------------------
# 5) LLM å¾Œç«¯å¯¦ä½œï¼ˆopenai èˆ‡ ollamaï¼‰
# ----------------------------
def call_llm_openai(model: str, system: str, user: str, temperature: float = 0.0) -> str:
    import requests
    api_key = BACKEND_CONFIG["openai_api_key"]
    api_base = BACKEND_CONFIG["openai_api_base"]
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY æœªè¨­å®š")

    url = f"{api_base}/chat/completions"
    payload = {
        "model": model,
        "temperature": temperature,
        "response_format": {"type": "json_object"},
        "messages": [
            {"role": "system", "content": system},
            {"role": "user", "content": user},
        ],
    }
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=120)
    r.raise_for_status()
    data = r.json()
    return data["choices"][0]["message"]["content"]

def call_llm_ollama(model: str, system: str, user: str, temperature: float = 0.0) -> str:
    import requests
    url = "http://127.0.0.1:11434/api/chat"
    payload = {
        "model": model,
        "options": {"temperature": temperature},
        "messages": [
            {"role": "system", "content": system},
            {"role": "user", "content": user}
        ],
        "format": "json"  # è¦æ±‚è¿”å› JSON
    }
    r = requests.post(url, data=json.dumps(payload), timeout=300)
    r.raise_for_status()
    data = r.json()
    # Ollama çš„ chat å›å‚³å¯èƒ½æ˜¯æµå¼ï¼›è‹¥éæµå¼ï¼Œdata æ‡‰åŒ…å« "message"
    if "message" in data and "content" in data["message"]:
        return data["message"]["content"]
    # è‹¥ç‚ºéå…¸å‹æ ¼å¼ï¼Œç›´æ¥å›å‚³å­—ä¸²åŒ–
    return json.dumps(data, ensure_ascii=False)

def call_llm(category: str, subject: str, body: str) -> Dict[str, Any]:
    user_prompt = USER_PROMPT_TEMPLATE.format(category=category, subject=subject or "", body=body or "")
    backend = BACKEND_CONFIG["backend"]
    model = BACKEND_CONFIG["model"]
    temp = BACKEND_CONFIG["temperature"]

    if backend == "openai":
        raw = call_llm_openai(model, SYSTEM_PROMPT, user_prompt, temp)
    elif backend == "ollama":
        raw = call_llm_ollama(model, SYSTEM_PROMPT, user_prompt, temp)
    else:
        raise ValueError(f"æœªçŸ¥ backend: {backend}")

    # è§£æ JSON
    try:
        data = json.loads(raw)
    except Exception:
        # è‹¥ LLM å¶çˆ¾åå‡ºå¤šé¤˜å­—å…ƒï¼Œå˜—è©¦ç²—æ¸…ç†
        raw = raw.strip()
        # å˜—è©¦æˆªå–æœ€å¤–å±¤ JSON
        first = raw.find("{")
        last = raw.rfind("}")
        if first >= 0 and last >= 0 and last > first:
            raw2 = raw[first:last+1]
            data = json.loads(raw2)
        else:
            raise
    return data

# ----------------------------
# 6) ä¸»æµç¨‹ï¼šè®€ parsed/*.jsonl -> é€ä»½æ–‡ä»¶æ‘˜è¦ -> è¼¸å‡º summaries/*.jsonl
# ----------------------------
def process_all(input_dir: Path, output_dir: Path, only_categories: Optional[List[str]] = None, limit: Optional[int] = None):
    output_dir.mkdir(exist_ok=True, parents=True)
    files = sorted(input_dir.glob("*.jsonl"))

    if only_categories:
        allowed = set(only_categories)
        files = [f for f in files if f.stem in allowed]

    if not files:
        print(f"âš ï¸ åœ¨ {input_dir} æ‰¾ä¸åˆ° .jsonl")
        return

    for infile in files:
        category = infile.stem  # æª”å -> é¡åˆ¥
        outfile = output_dir / f"{category}.jsonl"
        n_ok, n_err = 0, 0

        with open(infile, "r", encoding="utf-8") as fin, open(outfile, "w", encoding="utf-8") as fout:
            for i, line in enumerate(fin):
                if limit and i >= limit:
                    break
                try:
                    rec = json.loads(line)
                    subject = rec.get("subject", "") or ""
                    body = rec.get("body", "") or ""
                    llm_json = call_llm(category, subject, body)
                    final_json = validate_and_enhance(llm_json, category, subject, body)

                    # é™„å¸¶ filename å›å¯«ï¼Œæ–¹ä¾¿è¿½è¹¤
                    final_json["filename"] = rec.get("filename")
                    # ä¹Ÿå¯æŠŠ meta.doc_no æ‹‰åˆ° extra è®“å¾ŒçºŒå¥½ç”¨
                    if "meta" in rec and isinstance(rec["meta"], dict):
                        doc_no = rec["meta"].get("doc_no")
                        if doc_no:
                            final_json.setdefault("extra", {})
                            final_json["extra"]["doc_no"] = doc_no

                    fout.write(json.dumps(final_json, ensure_ascii=False) + "\n")
                    n_ok += 1
                except Exception as e:
                    n_err += 1
                    print(f"âŒ {infile.name} line {i+1}: {e}")

        print(f"âœ… {category}: æˆåŠŸ {n_ok} ç­†ï¼Œå¤±æ•— {n_err} ç­† -> {outfile}")

def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description="ä»¥ LLM å°å…¬æ–‡åšçµæ§‹åŒ–æ‘˜è¦ï¼ˆå«äººå/èº«åˆ†è­‰/ä¿å–®è³‡è¨Šï¼‰")
    p.add_argument("--input-dir", type=str, default="parsed", help="è¼¸å…¥ç›®éŒ„ï¼ˆextract_body.py çš„è¼¸å‡ºï¼‰")
    p.add_argument("--output-dir", type=str, default="summaries", help="è¼¸å‡ºç›®éŒ„ï¼ˆæ¯é¡åˆ¥ä¸€å€‹ .jsonlï¼‰")
    p.add_argument("--backend", type=str, choices=["openai", "ollama"], default=BACKEND_CONFIG["backend"])
    p.add_argument("--model", type=str, default=BACKEND_CONFIG["model"])
    p.add_argument("--categories", nargs="*", default=None, help="åªè™•ç†æŒ‡å®šé¡åˆ¥ï¼ˆæª”å stemï¼‰")
    p.add_argument("--limit", type=int, default=None, help="æ¯æª”å‰ N ç­†æ¸¬è©¦ç”¨")
    return p.parse_args()

def main():
    args = parse_args()
    BACKEND_CONFIG["backend"] = args.backend
    BACKEND_CONFIG["model"] = args.model

    print(f"ğŸš€ backend={args.backend}  model={args.model}")
    process_all(Path(args.input_dir), Path(args.output_dir), args.categories, args.limit)
    print("ğŸ‰ å®Œæˆ")

if __name__ == "__main__":
    main()
