# -*- coding: utf-8 -*-
"""
summarize_docs.py (Ollama å°ˆç”¨ç‰ˆ)
---------------------------------
è®€å– parsed/<category>.jsonlï¼ˆæ¯è¡Œä¸€ä»½æ–‡ä»¶ï¼šsubject/body/meta/filename/categoryï¼‰ï¼Œ
å‘¼å«æœ¬åœ° Ollama æŒ‡ä»¤æ¨¡å‹åšã€Œçµæ§‹åŒ–æ‘˜è¦ï¼ˆåªè¼¸å‡º JSONï¼‰ã€ï¼Œ
ä¸¦ç”¨æ­£å‰‡åšäºŒæ¬¡é©—è­‰/å¢è£œï¼ˆäººåã€èº«åˆ†è­‰ã€ä¿å–®è™Ÿï¼‰ã€‚

è¼¸å‡º summaries/<category>.jsonlï¼ˆæ¯è¡Œä¸€ç­†æ‘˜è¦ JSONï¼‰ã€‚

ç”¨æ³•ï¼š
  # å…ˆç¢ºèª ollama æœå‹™èˆ‡æ¨¡å‹å°±ç·’
  # ollama serve
  # ollama pull qwen2.5:7b-instruct   ï¼ˆæˆ–å…ˆç”¨è¼ƒå°æ¨¡å‹ qwen2.5:1.5b-instructï¼‰

  # å°é‡æ¸¬è©¦
  python summarize_docs.py --model qwen2.5:1.5b-instruct --limit 1

  # æŒ‡å®šé¡åˆ¥
  python summarize_docs.py --model qwen2.5:7b-instruct --categories ä¿å–®æŸ¥è©¢ --limit 5

  # é è¨­ï¼š
  #   input-dir = parsed
  #   output-dir = summaries
"""

import argparse
import json
import os
import re
import time
from pathlib import Path
from typing import Dict, Any, Optional, List

# =========================
# åŸºæœ¬è¨­å®š
# =========================

BACKEND_CONFIG = {
    "backend": "ollama",               # åƒ…æ”¯æ´ ollama
    "model": "qwen2.5:7b-instruct",    # ä¾ä½ æœ¬åœ°æ‹‰çš„æ¨¡å‹èª¿æ•´
    "temperature": 0.0,
}

# é•·æ–‡æˆªæ–·ï¼ˆé¿å…æœ¬åœ°å°æ¨¡å‹å¡ä½ï¼‰
MAX_CHARS = 3000

# æ­£å‰‡ï¼šå°ç£ ID / ä¿å–®è™Ÿï¼ˆç°¡åŒ–å•Ÿç™¼å¼ï¼‰
TW_ID_RE  = re.compile(r"\b[A-Z][0-9]{9}\b")
POLICY_RE = re.compile(r"\b[A-Z0-9]{8,20}\b", re.IGNORECASE)
CNAME_RE  = re.compile(r"[\u4e00-\u9fa5Â·]{2,4}")

# System èˆ‡ User Promptï¼ˆè¦æ±‚åªè¼¸å‡º JSONï¼‰
SYSTEM_PROMPT = "ä½ æ˜¯ä¸€å€‹åš´æ ¼çš„è³‡è¨ŠæŠ½å–å™¨ã€‚ä½ åªè¼¸å‡º JSONï¼Œçµ•ä¸å¤šèªªä¸€å¥è©±ã€‚"

USER_PROMPT_TEMPLATE = """è«‹æ ¹æ“šä»¥ä¸‹å…¬æ–‡å…§å®¹ï¼Œç”¢ç”Ÿçµæ§‹åŒ–æ‘˜è¦ï¼ˆJSON æ ¼å¼ã€UTF-8ã€strict JSONï¼‰ã€‚

ã€ä»»å‹™è¦æ±‚ã€‘
1. ç›®çš„ï¼šèƒå–é—œéµæ¬„ä½ï¼Œè‹¥æ²’æœ‰å°±å¡« nullã€‚
2. åƒ…è¼¸å‡º JSONï¼Œä¸è¦æ–‡å­—è§£é‡‹ã€ä¸è¦åŠ  ```jsonã€‚
3. æ¬„ä½èªªæ˜ï¼š
   - category: åŸå§‹é¡åˆ¥ï¼ˆå¦‚ï¼šä¿å–®æŸ¥è©¢/é€šçŸ¥å‡½/æ‰£æŠ¼å‘½ä»¤â€¦ï¼‰
   - title: 10~40 å­—å…§ä¸­æ–‡æ‘˜è¦æ¨™é¡Œ
   - summary: 100~200 å­—å…§è¦é»æ‘˜è¦ï¼ˆèª°ï¼å°èª°ï¼åšä»€éº¼ï¼ä½•æ™‚ï¼è¦æ±‚ï¼‰
   - persons: æ¶‰åŠä¹‹äººååˆ—è¡¨ï¼ˆä¸­æ–‡åç‚ºä¸»ï¼‰
   - ids: å¯èƒ½çš„èº«åˆ†è­‰å­—è™Ÿåˆ—è¡¨ï¼ˆæ ¼å¼ï¼š1 è‹±æ–‡ + 9 æ•¸å­—ï¼‰
   - policy_type: ä¿å–®ç¨®é¡ï¼ˆå£½éšª/æ„å¤–éšª/é†«ç™‚éšª/å‚·å®³éšª/ç«éšªï¼›è‹¥ä¸æ˜å¡« nullï¼‰
   - policy_numbers: ä¿å–®æˆ–å¥‘ç´„ç·¨è™Ÿåˆ—è¡¨ï¼ˆè‹±æ•¸ 8â€“20ï¼‰
   - actions: æœ¬æ–‡æ¶‰åŠä¹‹å‹•ä½œ/è¦æ±‚ï¼ˆå¦‚ï¼šæŸ¥è©¢ã€æ’¤éŠ·ã€æ‰£æŠ¼ã€é€šçŸ¥ã€è£œä»¶ï¼‰
   - date_mentions: æ–‡ä¸­é‡è¦æ—¥æœŸï¼ˆyyyy-mm-dd æˆ–æ°‘åœ‹ç´€å¹´åŸæ¨£ï¼‰
   - parties: æ¶‰åŠæ©Ÿé—œ/å…¬å¸/å–®ä½ååˆ—è¡¨
   - extra: å…¶ä»–é—œéµæ¬„ä½ï¼ˆå­—å…¸ï¼‰ï¼Œå¦‚æ¡ˆä»¶è™Ÿã€æ³•é™¢å­—è™Ÿã€é‡‘é¡ã€åœ°å€ã€é›»è©±ç­‰

ã€è¼¸å‡º JSON ç¯„ä¾‹ã€‘
{{
  "category": "{category}",
  "title": "â€¦",
  "summary": "â€¦",
  "persons": ["â€¦"],
  "ids": ["â€¦"],
  "policy_type": "å£½éšª",
  "policy_numbers": ["â€¦"],
  "actions": ["æŸ¥è©¢"],
  "date_mentions": ["æ°‘åœ‹114å¹´01æœˆ01æ—¥"],
  "parties": ["è‡ºç£è‡ºåŒ—åœ°æ–¹æ³•é™¢", "å…¨çƒäººå£½"],
  "extra": {{"doc_no": "åŒ—é™¢åŸ·æ™ºå­—ç¬¬123è™Ÿ"}}
}}

ã€æ–‡æœ¬ã€‘
<subject>
{subject}
</subject>

<body>
{body}
</body>
"""

# =========================
# å·¥å…·ï¼šé¬†å®¹éŒ¯ JSON è§£æ
# =========================

def safe_json_loads_loose(s: str) -> dict:
    """
    ç›¡åŠ›å¾ s ä¸­æ“·å–ç¬¬ä¸€å€‹åˆæ³• JSON ç‰©ä»¶ï¼š
      - ç§»é™¤ ```json ... ``` æˆ– ``` ... ```
      - æ‰¾å‡ºç¬¬ä¸€æ®µã€Œå¤§æ‹¬è™Ÿå¹³è¡¡ã€çš„ç‰‡æ®µ
      - å¿½ç•¥ JSON å¤–çš„é›œè¨Š
    å¤±æ•—å‰‡ä¸Ÿ ValueError
    """
    s = s.strip()

    # å»é™¤åœæ¬„ ```json / ``` åŒ…è£¹
    if s.startswith("```"):
        fence_end = s.find("```", 3)
        if fence_end != -1:
            inner = s[3:fence_end].strip()
            if inner.lower().startswith("json"):
                inner = inner[4:].strip()
            s = inner.strip()

    # ç›´æ¥å˜—è©¦
    try:
        return json.loads(s)
    except Exception:
        pass

    # å¾ç¬¬ä¸€å€‹ { èµ·ï¼Œåšæ‹¬è™Ÿå¹³è¡¡
    first = s.find("{")
    if first == -1:
        raise ValueError("No JSON object start '{' found.")

    stack = 0
    in_str = False
    esc = False
    end_idx = -1
    for i, ch in enumerate(s[first:], start=first):
        if in_str:
            if esc:
                esc = False
            elif ch == '\\':
                esc = True
            elif ch == '"':
                in_str = False
        else:
            if ch == '"':
                in_str = True
            elif ch == '{':
                stack += 1
            elif ch == '}':
                stack -= 1
                if stack == 0:
                    end_idx = i
                    break

    if end_idx == -1:
        raise ValueError("Unbalanced braces; cannot extract JSON object.")

    candidate = s[first:end_idx+1].strip()
    return json.loads(candidate)

# =========================
# Ollama å¾Œç«¯
# =========================

def call_llm_ollama(model: str, system: str, user: str, temperature: float = 0.0) -> str:
    import requests
    url = "http://127.0.0.1:11434/api/chat"
    payload = {
        "model": model,
        "options": {"temperature": temperature},
        "messages": [
            {"role": "system", "content": system},
            {"role": "user", "content": user}
        ],
        "format": "json",
        "stream": False  # éä¸²æµï¼Œå›å®Œæ•´ JSON
    }

    # ç°¡å–®é‡è©¦ï¼ˆä¸‹è¼‰/è¼‰å…¥æ¨¡å‹æ™‚è¼ƒæ…¢ï¼‰
    for attempt in range(3):
        try:
            resp = requests.post(url, data=json.dumps(payload), timeout=600)
            resp.raise_for_status()
            data = resp.json()
            msg = data.get("message") or {}
            content = msg.get("content", "")
            if not content and "messages" in data and isinstance(data["messages"], list) and data["messages"]:
                content = data["messages"][-1].get("content", "")
            return content
        except Exception as e:
            if attempt == 2:
                raise
            time.sleep(2 * (attempt + 1))

# =========================
# å¾Œè™•ç†ï¼šæ­£å‰‡æ ¡é©—/å¢è£œ
# =========================

def _unique_keep(seq: List[str]) -> List[str]:
    seen, out = set(), []
    for s in seq or []:
        s = str(s).strip()
        if s and s not in seen:
            seen.add(s)
            out.append(s)
    return out

def validate_and_enhance(record: Dict[str, Any], category: str, subject: str, body: str) -> Dict[str, Any]:
    out = dict(record)

    # personsï¼šè‹¥ç©ºï¼Œç”¨å•Ÿç™¼å¼è£œä¸­æ–‡å§“åå€™é¸
    persons = out.get("persons")
    if not isinstance(persons, list):
        persons = []
    candidates = CNAME_RE.findall(subject + "\n" + body)
    stop = {"é™„ä»¶", "èªªæ˜", "ä¸»æ—¨", "é€šçŸ¥", "æœ¬é™¢", "æœ¬å±€", "æœ¬å…¬å¸", "æ‰¿è¾¦", "æ‰¿è¾¦äºº", "å¾©æ–‡"}
    candidates = [c for c in candidates if c not in stop]
    out["persons"] = _unique_keep(list(persons) + candidates[:5])

    # idsï¼šæ­£å‰‡è£œ
    ids = out.get("ids")
    if not isinstance(ids, list):
        ids = []
    out["ids"] = _unique_keep(list(ids) + TW_ID_RE.findall(subject + "\n" + body))

    # policy_numbersï¼šæ­£å‰‡è£œ
    pols = out.get("policy_numbers")
    if not isinstance(pols, list):
        pols = []
    out["policy_numbers"] = _unique_keep(list(pols) + POLICY_RE.findall(subject + "\n" + body))

    # policy_typeï¼šç¼ºæ™‚ç”¨é—œéµè©è£œ
    if not out.get("policy_type"):
        s = subject + "\n" + body
        if "å£½éšª" in s:
            out["policy_type"] = "å£½éšª"
        elif "æ„å¤–éšª" in s:
            out["policy_type"] = "æ„å¤–éšª"
        elif "é†«ç™‚éšª" in s or "é†«ç™‚ä¿éšª" in s:
            out["policy_type"] = "é†«ç™‚éšª"
        elif "å‚·å®³éšª" in s:
            out["policy_type"] = "å‚·å®³éšª"
        elif "ç«éšª" in s:
            out["policy_type"] = "ç«éšª"
        else:
            out["policy_type"] = None

    # actionsï¼šç¼ºæ™‚ç”¨é—œéµè©è£œ
    if not out.get("actions"):
        s = subject + "\n" + body
        actions = []
        for k in ["æŸ¥è©¢", "æ’¤éŠ·", "æ‰£æŠ¼", "é€šçŸ¥", "è£œä»¶", "æ›´æ­£", "å‡½è¦†", "æª¢é€", "è½‰çŸ¥", "æ‹è³£", "åŸ·è¡Œ", "èª¿æŸ¥"]:
            if k in s:
                actions.append(k)
        out["actions"] = _unique_keep(actions) or None

    # extraï¼šç¢ºä¿å­—å…¸
    if not isinstance(out.get("extra"), dict):
        out["extra"] = {}

    # category è¦†å¯«ç‚ºä¾†æºï¼ˆé¿å…æ¨¡å‹äº‚æ”¹ï¼‰
    out["category"] = category

    return out

# =========================
# ä¸»æµç¨‹
# =========================

def call_llm(category: str, subject: str, body: str) -> Dict[str, Any]:
    if body and len(body) > MAX_CHARS:
        body = body[:MAX_CHARS] + "\nâ€¦(æˆªæ–·)â€¦"

    user_prompt = USER_PROMPT_TEMPLATE.format(
        category=category,
        subject=subject or "",
        body=body or ""
    )
    raw = call_llm_ollama(
        model=BACKEND_CONFIG["model"],
        system=SYSTEM_PROMPT,
        user=user_prompt,
        temperature=BACKEND_CONFIG["temperature"],
    )
    try:
        data = safe_json_loads_loose(raw)
    except Exception as e:
        preview = raw[:400].replace("\n", "\\n")
        raise ValueError(f"LLM å›å‚³éç´” JSONï¼š{e}; ç‰‡æ®µé è¦½={preview}")
    return data

def process_all(input_dir: Path, output_dir: Path, only_categories: Optional[List[str]] = None, limit: Optional[int] = None):
    output_dir.mkdir(exist_ok=True, parents=True)
    files = sorted(input_dir.glob("*.jsonl"))

    if only_categories:
        allowed = set(only_categories)
        files = [f for f in files if f.stem in allowed]

    if not files:
        print(f"âš ï¸ åœ¨ {input_dir} æ‰¾ä¸åˆ° .jsonl")
        return

    for infile in files:
        category = infile.stem
        outfile = output_dir / f"{category}.jsonl"
        n_ok, n_err = 0, 0

        with open(infile, "r", encoding="utf-8") as fin, open(outfile, "w", encoding="utf-8") as fout:
            for i, line in enumerate(fin):
                if limit and i >= limit:
                    break
                try:
                    rec = json.loads(line)
                except Exception as e:
                    n_err += 1
                    print(f"âŒ è¼¸å…¥ JSON è§£æå¤±æ•—: {infile.name} line {i+1}: {e}")
                    continue

                try:
                    subject = rec.get("subject", "") or ""
                    body = rec.get("body", "") or ""
                    llm_json = call_llm(category, subject, body)
                    final_json = validate_and_enhance(llm_json, category, subject, body)

                    # é™„åŠ ä¾†æºè³‡è¨Š
                    final_json["filename"] = rec.get("filename")
                    if "meta" in rec and isinstance(rec["meta"], dict):
                        doc_no = rec["meta"].get("doc_no")
                        if doc_no:
                            final_json.setdefault("extra", {})
                            final_json["extra"]["doc_no"] = doc_no

                    fout.write(json.dumps(final_json, ensure_ascii=False) + "\n")
                    n_ok += 1
                except Exception as e:
                    n_err += 1
                    print(f"âŒ {infile.name} line {i+1}: {e}")

        print(f"âœ… {category}: æˆåŠŸ {n_ok} ç­†ï¼Œå¤±æ•— {n_err} ç­† -> {outfile}")

def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description="ä»¥æœ¬åœ° Ollama å°å…¬æ–‡åšçµæ§‹åŒ–æ‘˜è¦ï¼ˆäººå/èº«åˆ†è­‰/ä¿å–®è³‡è¨Šï¼‰")
    p.add_argument("--input-dir", type=str, default="parsed", help="è¼¸å…¥ç›®éŒ„ï¼ˆextract_body.py çš„è¼¸å‡ºï¼‰")
    p.add_argument("--output-dir", type=str, default="summaries", help="è¼¸å‡ºç›®éŒ„ï¼ˆæ¯é¡åˆ¥ä¸€å€‹ .jsonlï¼‰")
    p.add_argument("--model", type=str, default=BACKEND_CONFIG["model"], help="Ollama æ¨¡å‹åç¨±ï¼Œå¦‚ qwen2.5:7b-instruct")
    p.add_argument("--categories", nargs="*", default=None, help="åªè™•ç†æŒ‡å®šé¡åˆ¥ï¼ˆæª”å stemï¼‰ï¼Œå¦‚ï¼šä¿å–®æŸ¥è©¢ é€šçŸ¥å‡½")
    p.add_argument("--limit", type=int, default=None, help="æ¯æª”å‰ N ç­†æ¸¬è©¦ç”¨")
    return p.parse_args()

def main():
    args = parse_args()
    BACKEND_CONFIG["model"] = args.model

    print(f"ğŸš€ backend=ollama  model={args.model}")
    process_all(Path(args.input_dir), Path(args.output_dir), args.categories, args.limit)
    print("ğŸ‰ å®Œæˆ")

if __name__ == "__main__":
    main()
