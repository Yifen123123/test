# -*- coding: utf-8 -*-
"""
summarize_docs.py (Ollama å°ˆç”¨ / èªªæ˜æ®µè½åŠ å¼·ç‰ˆ)
------------------------------------------------
è®€å– parsed/<category>.jsonlï¼ˆæ¯è¡Œä¸€ä»½ï¼šsubject/body/meta/filename/categoryï¼‰ï¼Œ
è‡ªå‹•æ“·å–ã€Œèªªæ˜ã€æ®µè½ï¼Œå‘¼å«æœ¬åœ° Ollama ç”¢ç”Ÿåš´æ ¼ JSON çš„çµæ§‹åŒ–æ‘˜è¦ï¼ˆå…¬å‹™å“¡è¦–è§’ï¼‰ï¼Œ
ä¸¦åšå¾Œè™•ç†ï¼ˆå§“å/èº«åˆ†è­‰/ä¿å–®è™Ÿ/insurer/å‹•ä½œè©/æœŸé™è£œå¼·ã€doc_no å›å¡«ï¼‰ã€‚

è¼¸å‡º summaries/<category>.jsonlï¼ˆæ¯è¡Œä¸€ç­†åš´æ ¼ JSONï¼‰ã€‚

ç”¨æ³•ï¼š
  # å…ˆç¢ºèª ollama èˆ‡æ¨¡å‹ï¼ˆå»ºè­° 3B èµ·æ­¥ï¼‰ï¼š
  #   ollama serve
  #   ollama pull qwen2.5:3b-instruct
  #
  # å°é‡æ¸¬è©¦ï¼ˆ1 ç­†ã€é ­å°¾æˆªæ–·ã€ä¸Šä¸‹æ–‡ 8192ï¼‰ï¼š
  #   python summarize_docs.py --model qwen2.5:3b-instruct --limit 1 --truncate-mode headtail --num-ctx 8192
  #
  # æŒ‡å®šé¡åˆ¥è·‘å¹¾ç­†ï¼š
  #   python summarize_docs.py --model qwen2.5:3b-instruct --categories ä¿å–®æŸ¥è©¢ --limit 5
"""

import argparse
import json
import re
import time
from pathlib import Path
from typing import Dict, Any, Optional, List
from urllib import request

# =========================
# åŸºæœ¬è¨­å®š
# =========================

BACKEND_CONFIG = {
    "backend": "ollama",
    "model": "qwen2.5:3b-instruct",   # å¯ç”¨ CLI è¦†è“‹
    "temperature": 0.0,
    "base_url": "http://127.0.0.1:11434",
}

MAX_CHARS_DEFAULT = 3000  # æ­£æ–‡æˆªæ–·ä¸Šé™ï¼ˆå¯ç”¨ --max-chars è¦†è“‹ï¼‰

# æ­£å‰‡ï¼šå°ç£èº«åˆ†è­‰ / ä¿å–®è™Ÿ / ä¸­æ–‡å§“å / æœŸé™
TW_ID_RE  = re.compile(r"\b[A-Z][0-9]{9}\b")
POLICY_RE = re.compile(r"\b[A-Z0-9]{8,20}\b", re.IGNORECASE)
CNAME_RE  = re.compile(r"[\u4e00-\u9fa5Â·]{2,4}")

# æœŸé™ï¼ˆä¾‹ï¼šè«‹æ–¼10æ—¥å…§ã€æœ€é²æ–¼æ°‘åœ‹113å¹´12æœˆ31æ—¥å‰ï¼‰
DEADLINE_PATTERNS = [
    re.compile(r"(?:è«‹æ–¼|æ‡‰æ–¼|æœ€é²æ–¼|é™æ–¼)\s*([0-9]{1,2})\s*æ—¥å…§"),
    re.compile(r"(?:è«‹æ–¼|æ‡‰æ–¼|æœ€é²æ–¼|é™æ–¼)\s*(æ°‘åœ‹[0-9]{2,3}å¹´[0-9]{1,2}æœˆ[0-9]{1,2}æ—¥)å‰?"),
    re.compile(r"(?:è«‹æ–¼|æ‡‰æ–¼|æœ€é²æ–¼|é™æ–¼)\s*([0-9]{4}[/-][0-9]{1,2}[/-][0-9]{1,2})å‰?"),
    re.compile(r"(?:æœ€é²|æœŸé™|é™æœŸ)ç‚º?\s*(æ°‘åœ‹[0-9]{2,3}å¹´[0-9]{1,2}æœˆ[0-9]{1,2}æ—¥|[0-9]{4}[/-][0-9]{1,2}[/-][0-9]{1,2})")
]

ROLE_STOPWORDS = {"å‚µå‹™äºº", "æ‰¿è¾¦", "æ‰¿è¾¦äºº", "è¢«å‘Š", "ç”³è«‹äºº", "é€šçŸ¥", "ä¸»æ—¨", "èªªæ˜", "é™„ä»¶", "æœ¬é™¢", "æœ¬å±€", "æœ¬å…¬å¸"}

KNOWN_INSURERS = [
    "å…¨çƒäººå£½", "å°ç£äººå£½", "è‡ºç£äººå£½", "åœ‹æ³°äººå£½", "æ–°å…‰äººå£½", "å¯Œé‚¦äººå£½", "å—å±±äººå£½", "ä¸­åœ‹äººå£½",
    "å‹é‚¦äººå£½", "é é›„äººå£½", "å®æ³°äººå£½", "å®‰è¯äººå£½", "æ³•åœ‹å·´é»äººå£½", "ä¿å¾·ä¿¡äººå£½"
]

# =========================
# Promptï¼šSystem / Schema / User
# =========================

SYSTEM_PROMPT = (
    "ä½ æ˜¯ä¸€ä½å…¬å‹™æ©Ÿé—œæ–‡æ›¸æ‰¿è¾¦è¦–è§’çš„è³‡è¨ŠæŠ½å–å™¨ã€‚ä½ åªè¼¸å‡º JSONï¼ˆåš´æ ¼ç¬¦åˆæˆ‘æä¾›çš„ schemaï¼‰ï¼Œ"
    "ä¸å¯è¼¸å‡ºå…¶å®ƒä»»ä½•æ–‡å­—ã€è¨»è§£æˆ–Markdownåœæ¬„ã€‚å°æ–¼ä¸ç¢ºå®šçš„æ¬„ä½ï¼Œè«‹è¼¸å‡º null æˆ–ç©ºé™£åˆ—ï¼Œä¸è¦çŒœæ¸¬ã€‚"
)

SCHEMA_JSON = r'''{
  "category": "string",
  "title": "string",
  "summary": "string",
  "persons": [
    {"name": "string", "id_number": "string|null"}
  ],
  "policy_numbers": ["string"],
  "policy_type": "string|null",
  "insurer": "string|null",
  "actions": ["string"],
  "date_mentions": ["string"],

  "deadline": "string|null",
  "rationale_points": ["string"],
  "required_documents": ["string"],
  "agent_todo": ["string"],

  "extra": {
    "doc_no": "string|null",
    "court": "string|null",
    "insured_name": "string|null",
    "policy_holder": "string|null"
  }
}'''

USER_PROMPT_TEMPLATE = """è«‹ä¾ä¸‹åˆ—ã€è¼¸å‡ºè¦æ ¼ã€‘èˆ‡ã€è¦å‰‡ã€‘ï¼Œå¾å…¬æ–‡æ–‡æœ¬èƒå–è³‡è¨Šï¼Œåƒ…è¼¸å‡ºä¸€å€‹ JSON ç‰©ä»¶ï¼ˆå…¬å‹™å“¡è¦–è§’ã€ç”¨è©ç²¾ç¢ºï¼‰ã€‚

ã€è¼¸å‡ºè¦æ ¼(JSON schema)ã€‘
{SCHEMA_JSON}

ã€è¦å‰‡ï¼ˆå‹™å¿…éµå®ˆï¼‰ã€‘
1) åƒ…è¼¸å‡º JSONï¼Œä¸å¾—å«æœ‰å¤šé¤˜æ–‡å­—æˆ–è¨»è§£ã€‚
2) personsï¼šåªæ”¾ã€Œç´”å§“åã€ï¼Œä¸å¯å‡ºç¾ã€Œå‚µå‹™äºº/æ‰¿è¾¦äºº/è¢«å‘Š/ç”³è«‹äººã€ç­‰è§’è‰²è©ã€‚
   - è‹¥æ–‡æœ¬ç‚ºã€Œå‚µå‹™äººç‹å°æ˜ã€ï¼Œpersons.name åªå¯«ã€Œç‹å°æ˜ã€ã€‚
   - è‹¥æ‰¾ä¸åˆ°å°æ‡‰èº«åˆ†è­‰ï¼Œid_number=nullï¼›è‹¥æ‰¾åˆ°ï¼Œå¿…é ˆèˆ‡è©²å§“åé…å°ã€‚
   - èº«åˆ†è­‰å¿…é ˆç¬¦åˆ 1 è‹±æ–‡ + 9 æ•¸å­—ï¼ˆä¾‹å¦‚ A123456789ï¼‰ï¼Œå¦å‰‡è¨­ç‚º nullã€‚
3) policy_numbersï¼šåªæ”¾ä¿å–®/å¥‘ç´„ç·¨è™Ÿï¼ˆè‹±æ•¸ 8â€“20 å­—å…ƒï¼‰ï¼Œæ’é™¤æ³•é™¢æ–‡è™Ÿ/ä¸€èˆ¬ä»£ç¢¼ã€‚
4) insurerï¼šå¡«ä¿éšªå…¬å¸å®˜æ–¹åç¨±ï¼ˆå¦‚ï¼šå…¨çƒäººå£½/å°ç£äººå£½ï¼‰ï¼Œè‹¥ç„¡å‰‡ nullã€‚
5) summaryï¼š60â€“160å­—ï¼Œä»¥ã€Œå…¬æ–‡æœ€ä¸»è¦ç”¨æ„ã€èˆ‡ã€Œè¦æ±‚å°è±¡/å‹•ä½œã€ç‚ºæ ¸å¿ƒï¼ˆå…¬å‹™å“¡è¦–è§’ï¼‰ã€‚
6) rationale_pointsï¼šåƒ…æ ¹æ“šã€èªªæ˜ç¯€éŒ„ã€‘çš„æ¢åˆ—æˆ–æ–‡å­—ï¼Œæ•´ç† 1â€“5 é»çŸ­å¥ï¼Œä¿ç•™åŸé †åºèˆ‡é—œéµäº‹ç”±/æ³•æº/äº‹è­‰ã€‚
7) agent_todoï¼šä»¥æ¥­å‹™å“¡å¯¦ä½œè¦–è§’ï¼Œåˆ—å‡º 1â€“5 æ¢å¯åŸ·è¡Œå¾…è¾¦ï¼ˆå‹•è©é–‹é ­ï¼‰ï¼Œä¾‹å¦‚ã€ŒæŸ¥è©¢ä¸¦æä¾›XXXä¹‹ä¿å–®è³‡æ–™ã€ã€ã€Œæ–¼æœŸé™å‰å›è¦†æ³•é™¢ã€ã€‚
8) deadlineï¼šè‹¥æ–‡ä¸­å‡ºç¾ã€Œè«‹æ–¼Xæ—¥å…§ã€ã€Œæœ€é²æ–¼YYYY/MM/DDå‰ã€ç­‰æœŸé™ï¼ŒåŸæ¨£è¼¸å‡ºï¼›ç„¡å‰‡ nullã€‚
9) required_documentsï¼šè‹¥æœ‰ã€Œæª¢é™„/æä¾›ä»¥ä¸‹è³‡æ–™ã€ç­‰è¦æ±‚ï¼Œæ•´ç†ç‚ºæ¸…å–®ï¼›ç„¡å‰‡ç©ºé™£åˆ—ã€‚
10) actionsï¼šå¾æ–‡ä¸­æŠ½å–ï¼ˆæŸ¥è©¢/æ’¤éŠ·/æ‰£æŠ¼/é€šçŸ¥/è£œä»¶/æ›´æ­£/å‡½è¦†/æª¢é€/è½‰çŸ¥/åŸ·è¡Œ/èª¿æŸ¥ï¼‰ï¼Œæ²’æœ‰å°±ç©ºé™£åˆ—ã€‚
11) ä¸ç¢ºå®šæ™‚å¯§å¯è¨­ç‚º null æˆ–ç©ºé™£åˆ—ï¼Œä¸è¦çŒœã€‚

ã€ç¯„ä¾‹ï¼ˆç¤ºæ„ï¼‰ã€‘
<subject>é—œæ–¼æŸ¥è©¢å‚µå‹™äººä¿å–®è³‡æ–™</subject>
<body>æœ¬é™¢é€šçŸ¥ï¼šè«‹å…¨çƒäººå£½æä¾›ç‹å°æ˜ï¼ˆèº«åˆ†è­‰A123456789ï¼‰åä¸‹å£½éšªä¿å–®PL20250101ä¹‹ç›¸é—œè³‡æ–™ï¼Œä»¥åˆ©åŸ·è¡Œã€‚</body>
<explain>
ä¸€ã€ä¾å¼·åˆ¶åŸ·è¡Œéœ€æ±‚ï¼Œéœ€ç¢ºèªå‚µå‹™äººä¿å–®è³‡ç”¢ã€‚
äºŒã€å‰æ¡ˆè³‡æ–™ä¸è¶³ï¼Œè«‹è£œé½Šã€‚
</explain>

å°æ‡‰è¼¸å‡ºï¼š
{{
  "category": "{category}",
  "title": "æ³•é™¢è«‹æ±‚æä¾›ç‹å°æ˜ä¹‹å£½éšªä¿å–®è³‡æ–™",
  "summary": "æœ¬é™¢å‡½è«‹å…¨çƒäººå£½æä¾›ç‹å°æ˜åä¸‹å£½éšªä¿å–®PL20250101ä¹‹è³‡æ–™ï¼Œä»¥é…åˆæ³•é™¢å¼·åˆ¶åŸ·è¡Œç¨‹åºã€‚",
  "persons": [{{"name": "ç‹å°æ˜", "id_number": "A123456789"}}],
  "policy_numbers": ["PL20250101"],
  "policy_type": "å£½éšª",
  "insurer": "å…¨çƒäººå£½",
  "actions": ["æŸ¥è©¢", "é€šçŸ¥"],
  "date_mentions": [],
  "deadline": null,
  "rationale_points": ["ä¾å¼·åˆ¶åŸ·è¡Œç¨‹åºéœ€ç¢ºèªä¿å–®è³‡ç”¢", "å‰æ¡ˆè³‡æ–™ä¸è¶³ï¼Œéœ€è£œé½Š"],
  "required_documents": ["ç‹å°æ˜åä¸‹å£½éšªä¿å–®PL20250101ä¹‹åŸºæœ¬è³‡æ–™èˆ‡ç‹€æ…‹"],
  "agent_todo": ["æŸ¥è©¢ç‹å°æ˜ä¹‹PL20250101ä¿å–®è³‡æ–™ä¸¦å½™æ•´", "å°‡è³‡æ–™å›è¦†æœ¬é™¢ï¼ˆä¾æŒ‡å®šæ ¼å¼/ç®¡é“ï¼‰"],
  "extra": {{"doc_no": null, "court": "æœ¬é™¢", "insured_name": "ç‹å°æ˜", "policy_holder": null}}
}}

ã€å¾…è™•ç†æ–‡æœ¬ã€‘
<subject>
{subject}
</subject>

<body>
{body}
</body>

ã€èªªæ˜ç¯€éŒ„ï¼ˆè‹¥ç„¡å‰‡ç©ºï¼‰ã€‘
<explain>
{explain}
</explain>
"""

# =========================
# å·¥å…·ï¼šHTTPã€JSON å®¹éŒ¯ã€æˆªæ–·ã€æ®µè½æ“·å–
# =========================

def http_post_json(url: str, payload: Dict[str, Any], timeout: int = 600) -> Dict[str, Any]:
    data = json.dumps(payload).encode("utf-8")
    req = request.Request(url, data=data, headers={"Content-Type": "application/json"}, method="POST")
    with request.urlopen(req, timeout=timeout) as resp:
        raw = resp.read()
        return json.loads(raw.decode("utf-8"))

def safe_json_loads_loose(s: str) -> dict:
    s = s.strip()
    if s.startswith("```"):
        fence_end = s.find("```", 3)
        if fence_end != -1:
            inner = s[3:fence_end].strip()
            if inner.lower().startswith("json"):
                inner = inner[4:].strip()
            s = inner.strip()
    try:
        return json.loads(s)
    except Exception:
        pass
    first = s.find("{")
    if first == -1:
        raise ValueError("No JSON object start '{' found.")
    stack = 0; in_str = False; esc = False; end_idx = -1
    for i, ch in enumerate(s[first:], start=first):
        if in_str:
            if esc: esc = False
            elif ch == '\\': esc = True
            elif ch == '"': in_str = False
        else:
            if ch == '"': in_str = True
            elif ch == '{': stack += 1
            elif ch == '}':
                stack -= 1
                if stack == 0:
                    end_idx = i; break
    if end_idx == -1:
        raise ValueError("Unbalanced braces; cannot extract JSON object.")
    candidate = s[first:end_idx+1].strip()
    return json.loads(candidate)

def truncate_text(text: str, max_chars: int, mode: str = "headtail") -> str:
    if not text or len(text) <= max_chars:
        return text
    if mode == "head":
        return text[:max_chars] + f"\nâ€¦(å·²æˆªæ–·ï¼ŒåŸé•· {len(text)} å­—)â€¦"
    head = max_chars // 2
    tail = max_chars - head
    return text[:head] + f"\nâ€¦(ä¸­ç•¥ï¼ŒåŸé•· {len(text)} å­—ï¼Œå·²æˆªæ–·)â€¦\n" + text[-tail:]

# --- ã€Œèªªæ˜ã€æ®µè½æ“·å–ï¼šå¾ body ä¸­åˆ‡å‡ºã€Œèªªæ˜ã€åˆ°ä¸‹ä¸€æ®µæ¨™é ­æˆ–çµå°¾ ---
SECTION_HEAD_RE = re.compile(r"^\s*(ä¸»æ—¨|èªªæ˜|è¾¦æ³•|ä¾æ“š|æ³•æº|æª¢é™„|é™„ä»¶|æ³¨æ„äº‹é …|æ­¤è‡´)\s*[:ï¼š]?\s*$", re.MULTILINE)
BULLET_RE = re.compile(r"^\s*(?:[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]\s*[ã€.]|[0-9]+\s*[).ã€]|â€¢|-)\s*(.+)$", re.MULTILINE)

def extract_explain_segment(body: str) -> str:
    if not body:
        return ""
    # æ‰¾å‡ºæ‰€æœ‰æ®µæ¨™é ­ä½ç½®
    matches = list(SECTION_HEAD_RE.finditer(body))
    if not matches:
        return ""
    # æ‰¾åˆ°æœ€è¿‘ä¸€å€‹ã€Œèªªæ˜ã€æ¨™é ­
    idx = None
    for i, m in enumerate(matches):
        if m.group(1) == "èªªæ˜":
            idx = i
    if idx is None:
        return ""
    start = matches[idx].end()
    end = len(body)
    if idx + 1 < len(matches):
        end = matches[idx + 1].start()
    segment = body[start:end].strip()
    return segment

def extract_explain_bullets(segment: str, max_points: int = 6) -> List[str]:
    if not segment:
        return []
    bullets = [m.group(1).strip() for m in BULLET_RE.finditer(segment)]
    # è‹¥æ²’åµæ¸¬åˆ°æ¢åˆ—ï¼Œå–å‰å¹¾è¡ŒåšçŸ­å¥
    if not bullets:
        lines = [ln.strip(" ã€€") for ln in segment.splitlines() if ln.strip()]
        bullets = lines[:max_points]
    return bullets[:max_points]

# =========================
# Ollama å¾Œç«¯
# =========================

def call_llm_ollama(model: str, system: str, user: str, temperature: float = 0.0, num_ctx: Optional[int] = None) -> str:
    url = f"{BACKEND_CONFIG['base_url']}/api/chat"
    options: Dict[str, Any] = {"temperature": temperature}
    if num_ctx:
        options["num_ctx"] = num_ctx
    payload = {
        "model": model,
        "options": options,
        "messages": [
            {"role": "system", "content": system},
            {"role": "user", "content": user}
        ],
        "format": "json",
        "stream": False
    }
    for attempt in range(3):
        try:
            data = http_post_json(url, payload, timeout=600)
            msg = data.get("message") or {}
            content = msg.get("content", "")
            if not content and "messages" in data and isinstance(data["messages"], list) and data["messages"]:
                content = data["messages"][-1].get("content", "")
            return content
        except Exception:
            if attempt == 2:
                raise
            time.sleep(2 * (attempt + 1))

# =========================
# å¾Œè™•ç†ï¼šè£œå¼·/æ ¡é©—
# =========================

def _unique_keep(seq: List[str]) -> List[str]:
    seen, out = set(), []
    for s in seq or []:
        s = str(s).strip()
        if s and s not in seen:
            seen.add(s); out.append(s)
    return out

def ensure_schema_keys(rec: Dict[str, Any]) -> Dict[str, Any]:
    out = dict(rec)
    # æ—¢æœ‰
    out.setdefault("category", None)
    out.setdefault("title", ""); out.setdefault("summary", "")
    if not isinstance(out.get("persons"), list): out["persons"] = []
    if not isinstance(out.get("policy_numbers"), list): out["policy_numbers"] = []
    if "policy_type" not in out: out["policy_type"] = None
    if "insurer" not in out: out["insurer"] = None
    if not isinstance(out.get("actions"), list): out["actions"] = []
    if not isinstance(out.get("date_mentions"), list): out["date_mentions"] = []
    if not isinstance(out.get("extra"), dict): out["extra"] = {}
    out["extra"].setdefault("doc_no", None)
    out["extra"].setdefault("court", None)
    out["extra"].setdefault("insured_name", None)
    out["extra"].setdefault("policy_holder", None)
    # æ–°å¢
    out.setdefault("deadline", None)
    if not isinstance(out.get("rationale_points"), list): out["rationale_points"] = []
    if not isinstance(out.get("required_documents"), list): out["required_documents"] = []
    if not isinstance(out.get("agent_todo"), list): out["agent_todo"] = []
    return out

def validate_and_enhance(record: Dict[str, Any], category: str, subject: str, body: str) -> Dict[str, Any]:
    out = ensure_schema_keys(record)
    s = f"{subject}\n{body}"

    # personsï¼šæœŸæœ› [{"name","id_number"}]
    persons_in = out.get("persons", [])
    persons: List[Dict[str, Any]] = []
    for p in persons_in:
        if isinstance(p, dict):
            name = str(p.get("name", "")).strip()
            idn  = p.get("id_number", None)
            if name and name not in ROLE_STOPWORDS:
                if isinstance(idn, str):
                    idn = idn.strip()
                    if not TW_ID_RE.fullmatch(idn):
                        idn = None
                else:
                    idn = None if idn is not None else None
                persons.append({"name": name, "id_number": idn})
    # è‹¥æ¨¡å‹æ¼æŠ“å§“åï¼Œå¾æ–‡æœ¬è£œ3å€‹å€™é¸
    cand_names = [c for c in CNAME_RE.findall(s) if c not in ROLE_STOPWORDS]
    existing = {p["name"] for p in persons}
    for n in cand_names:
        if n not in existing and len(persons) < 3:
            persons.append({"name": n, "id_number": None})
            existing.add(n)
    out["persons"] = persons

    # policy_numbersï¼šæ­£å‰‡è£œ
    pols = _unique_keep(list(out.get("policy_numbers", [])) + POLICY_RE.findall(s))
    out["policy_numbers"] = pols

    # policy_type é—œéµè©è£œ
    if not out.get("policy_type"):
        if "å£½éšª" in s: out["policy_type"] = "å£½éšª"
        elif "æ„å¤–éšª" in s: out["policy_type"] = "æ„å¤–éšª"
        elif "é†«ç™‚éšª" in s or "é†«ç™‚ä¿éšª" in s: out["policy_type"] = "é†«ç™‚éšª"
        elif "å‚·å®³éšª" in s: out["policy_type"] = "å‚·å®³éšª"
        elif "ç«éšª" in s: out["policy_type"] = "ç«éšª"
        else: out["policy_type"] = None

    # actions é—œéµè©è£œ
    if not out.get("actions"):
        acts = []
        for k in ["æŸ¥è©¢","æ’¤éŠ·","æ‰£æŠ¼","é€šçŸ¥","è£œä»¶","æ›´æ­£","å‡½è¦†","æª¢é€","è½‰çŸ¥","åŸ·è¡Œ","èª¿æŸ¥"]:
            if k in s: acts.append(k)
        out["actions"] = _unique_keep(acts)

    # insurerï¼šè‹¥ç¼ºå‰‡å¾æ­£æ–‡è£œ
    if not out.get("insurer"):
        for kw in KNOWN_INSURERS:
            if kw in s:
                out["insurer"] = kw; break

    # deadlineï¼šè‹¥ç¼ºå‰‡ç”¨æ­£å‰‡è£œ
    if not out.get("deadline"):
        dl = []
        for pat in DEADLINE_PATTERNS:
            for m in pat.finditer(s):
                g = [x for x in m.groups() if x]
                dl.extend(g)
        out["deadline"] = dl[0] if dl else None

    # category è¦†å¯«ä¾†æº
    out["category"] = category
    return out

# =========================
# ä¸»æµç¨‹
# =========================

def build_user_prompt(category: str, subject: str, body: str, explain: str) -> str:
    return USER_PROMPT_TEMPLATE.format(
        SCHEMA_JSON=SCHEMA_JSON,
        category=category,
        subject=subject or "",
        body=body or "",
        explain=explain or ""
    )

def call_llm(category: str, subject: str, body: str, explain: str, max_chars: int,
             truncate_mode: str = "headtail", num_ctx: Optional[int] = None) -> Dict[str, Any]:
    body_for_llm = truncate_text(body, max_chars, mode=truncate_mode) if body and len(body) > max_chars else (body or "")
    # èªªæ˜æ®µä¿ç•™è¼ƒå®Œæ•´ï¼Œä½†ä¹Ÿåšé©åº¦ä¸Šé™ï¼ˆé¿å…çˆ† contextï¼‰
    explain_trunc = truncate_text(explain, max(800, max_chars // 2), mode="head") if explain and len(explain) > max(800, max_chars // 2) else (explain or "")
    user_prompt = build_user_prompt(category, subject, body_for_llm, explain_trunc)

    raw = call_llm_ollama(
        model=BACKEND_CONFIG["model"],
        system=SYSTEM_PROMPT,
        user=user_prompt,
        temperature=BACKEND_CONFIG["temperature"],
        num_ctx=num_ctx,
    )
    try:
        data = safe_json_loads_loose(raw)
    except Exception as e:
        preview = raw[:400].replace("\n", "\\n")
        raise ValueError(f"LLM å›å‚³éç´” JSONï¼š{e}; ç‰‡æ®µé è¦½={preview}")
    return data

def process_all(input_dir: Path, output_dir: Path,
                only_categories: Optional[List[str]] = None,
                limit: Optional[int] = None,
                max_chars: int = MAX_CHARS_DEFAULT,
                truncate_mode: str = "headtail",
                num_ctx: Optional[int] = None) -> None:
    output_dir.mkdir(exist_ok=True, parents=True)
    files = sorted(input_dir.glob("*.jsonl"))

    if only_categories:
        allowed = set(only_categories)
        files = [f for f in files if f.stem in allowed]

    if not files:
        print(f"âš ï¸ åœ¨ {input_dir} æ‰¾ä¸åˆ° .jsonl")
        return

    for infile in files:
        category = infile.stem
        outfile = output_dir / f"{category}.jsonl"
        n_ok, n_err = 0, 0

        with open(infile, "r", encoding="utf-8") as fin, open(outfile, "w", encoding="utf-8") as fout:
            for i, line in enumerate(fin):
                if limit and i >= limit:
                    break
                try:
                    rec = json.loads(line)
                except Exception as e:
                    n_err += 1
                    print(f"âŒ è¼¸å…¥ JSON è§£æå¤±æ•—: {infile.name} line {i+1}: {e}")
                    continue

                try:
                    subject = rec.get("subject", "") or ""
                    body = rec.get("body", "") or ""
                    # æ“·å–ã€Œèªªæ˜ã€æ®µ
                    explain_seg = extract_explain_segment(body)
                    # å¦‚é‡æ²’æœ‰æ¨™é ­ï¼Œè©¦åœ–å¾æ¢åˆ—æ¨æ¸¬èªªæ˜
                    if not explain_seg:
                        # è‹¥æ­£æ–‡ä¸­æ¢åˆ—å¾ˆå¤šï¼Œå–å‰ 6 æ¢ç•¶ä½œèªªæ˜å€™é¸ï¼ˆä¿å®ˆï¼‰
                        bullets = extract_explain_bullets(body, max_points=6)
                        explain_seg = "\n".join(bullets)

                    llm_json = call_llm(
                        category, subject, body, explain_seg,
                        max_chars=max_chars, truncate_mode=truncate_mode, num_ctx=num_ctx
                    )
                    final_json = validate_and_enhance(llm_json, category, subject, body)

                    # é™„åŠ ä¾†æºè³‡è¨Š
                    final_json["filename"] = rec.get("filename")
                    # å›å¡«æ–‡è™Ÿåˆ° extra.doc_noï¼ˆè‹¥æœ‰ï¼‰
                    if "meta" in rec and isinstance(rec["meta"], dict):
                        doc_no = rec["meta"].get("doc_no")
                        if doc_no:
                            final_json.setdefault("extra", {})
                            final_json["extra"]["doc_no"] = doc_no

                    fout.write(json.dumps(final_json, ensure_ascii=False) + "\n")
                    n_ok += 1
                except Exception as e:
                    n_err += 1
                    print(f"âŒ {infile.name} line {i+1}: {e}")

        print(f"âœ… {category}: æˆåŠŸ {n_ok} ç­†ï¼Œå¤±æ•— {n_err} ç­† -> {outfile}")

def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description="ä»¥æœ¬åœ° Ollama å°å…¬æ–‡åšçµæ§‹åŒ–æ‘˜è¦ï¼ˆå«èªªæ˜æ®µè½ã€æ¥­å‹™å“¡å¾…è¾¦ï¼‰")
    p.add_argument("--input-dir", type=str, default="parsed", help="è¼¸å…¥ç›®éŒ„ï¼ˆextract_body.py çš„è¼¸å‡ºï¼‰")
    p.add_argument("--output-dir", type=str, default="summaries", help="è¼¸å‡ºç›®éŒ„ï¼ˆæ¯é¡åˆ¥ä¸€å€‹ .jsonlï¼‰")
    p.add_argument("--model", type=str, default=BACKEND_CONFIG["model"], help="Ollama æ¨¡å‹åç¨±ï¼Œå¦‚ qwen2.5:3b-instruct")
    p.add_argument("--categories", nargs="*", default=None, help="åªè™•ç†æŒ‡å®šé¡åˆ¥ï¼ˆæª”å stemï¼‰ï¼Œå¦‚ï¼šä¿å–®æŸ¥è©¢ é€šçŸ¥å‡½")
    p.add_argument("--limit", type=int, default=None, help="æ¯æª”å‰ N ç­†æ¸¬è©¦ç”¨")
    p.add_argument("--max-chars", type=int, default=MAX_CHARS_DEFAULT, help="æ­£æ–‡æœ€å¤§å­—å…ƒæ•¸ï¼ˆè¶…éæœƒæˆªæ–·ï¼‰")
    p.add_argument("--truncate-mode", choices=["head", "headtail"], default="headtail",
                   help="æˆªæ–·ç­–ç•¥ï¼šhead=åªç•™é–‹é ­ã€headtail=ä¿ç•™é ­å°¾ï¼ˆé è¨­ï¼‰")
    p.add_argument("--num-ctx", type=int, default=None,
                   help="Ollama context tokensï¼ˆå¦‚ 8192/16384ï¼Œéœ€æ¨¡å‹æ”¯æ´ï¼‰")
    return p.parse_args()

def main():
    args = parse_args()
    BACKEND_CONFIG["model"] = args.model
    print(f"ğŸš€ backend=ollama  model={args.model}  max_chars={args.max_chars}  truncate_mode={args.truncate_mode}  num_ctx={args.num_ctx}")
    process_all(
        Path(args.input_dir),
        Path(args.output_dir),
        args.categories,
        args.limit,
        max_chars=args.max_chars,
        truncate_mode=args.truncate_mode,
        num_ctx=args.num_ctx,
    )
    print("ğŸ‰ å®Œæˆ")

if __name__ == "__main__":
    main()
