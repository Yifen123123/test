# -*- coding: utf-8 -*-
"""
æƒæ E5+Chroma åˆ†é¡å™¨çš„æ±ºç­–é–€æª»ï¼š
1) å…¨åŸŸé–€æª»ï¼šthr_sim Ã— thr_margin â†’ æ‰¾æœ€ä½³ Macro-F1
2) (å¯é¸) æ¯é¡åˆ¥å¾®èª¿ï¼šåœ¨å…¨åŸŸæœ€ä½³åŸºç¤ä¸Šï¼Œé€é¡åˆ¥æƒ sim æˆ– margin çš„æœ€ä½³å€¼
è¼¸å‡ºï¼š
- best_global.txt / best_per_class.txt
- pred_global.csv / pred_per_class.csv
- per_class_thr.jsonï¼ˆè‹¥æœ‰å¾®èª¿ï¼‰
- features.parquetï¼ˆæ¯ç­†çš„ top1, max_sim, margin, p1ï¼Œä¾›é‡è¤‡å¯¦é©—é‡ç”¨ï¼‰

éœ€æ±‚ï¼špip install pandas numpy scikit-learn pyarrow sentence-transformers chromadb
"""
import argparse, json, re
from dataclasses import dataclass
from typing import Dict, List, Tuple
from pathlib import Path

import numpy as np
import pandas as pd
from sklearn.metrics import f1_score, classification_report, accuracy_score

import chromadb
from sentence_transformers import SentenceTransformer

# ========= èˆ‡ classify.py åŒæ­¥çš„å¸¸æ•¸/è¦å‰‡ =========
PERSIST_DIR = "chroma_db"
COLLECTION_NAME = "gov_letters"
EMBED_MODEL = "intfloat/multilingual-e5-large"

# èˆ‡ classify.py ä¿æŒä¸€è‡´ï¼ˆå¾®åŠ æ¬Šèˆ‡å…ˆé©—ï¼‰
RULES = {
    "ä¿å–®æŸ¥è©¢ï¼‹è¨»è¨˜": ["è¨»è¨˜", "å‚™è¨»", "åŠ è¨»", "æ›´æ­£è¨»è¨˜", "è£œè¨»è¨˜"]
}
RULE_BONUS = 0.05
CLASS_PRIOR: Dict[str, float] = {
    # "ä¿å–®æŸ¥è©¢": 1.0,
    # "ä¿å–®æŸ¥è©¢ï¼‹è¨»è¨˜": 1.05,
}

# ========= åŸºç¤å·¥å…· =========
def pick_device(name: str = "auto") -> str:
    name = (name or "auto").lower()
    try:
        import torch
    except Exception:
        return "cpu"
    if name != "auto":
        return name
    if torch.cuda.is_available():
        return "cuda"
    if getattr(torch.backends, "mps", None) and torch.backends.mps.is_available():
        return "mps"
    return "cpu"

def softmax_dict(votes: Dict[str, float], T: float = 1.0) -> Dict[str, float]:
    if not votes:
        return {"Other": 1.0}
    labels = list(votes.keys())
    vals = np.array([votes[l] for l in labels], dtype=np.float64)
    vals = vals / max(T, 1e-6)
    vals -= vals.max()
    p = np.exp(vals); p /= (p.sum() + 1e-12)
    return {labels[i]: float(p[i]) for i in range(len(labels))}

@dataclass
class CoreFeat:
    text: str
    y_true: str
    top1: str       # ç¥¨æ•¸æœ€é«˜çš„ labelï¼ˆæœªå¥—é–€æª»ï¼‰
    max_sim: float  # è©² top1 label çš„æœ€å¤§ç›¸ä¼¼åº¦
    margin: float   # ç¥¨æ•¸å·®ï¼šscore(top1) - score(top2)
    p1: float       # softmax(votes)[top1]

class E5Embedder:
    def __init__(self, model_name=EMBED_MODEL, device="auto"):
        dev = pick_device(device)
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è£ç½®ï¼š{dev}")
        self.model = SentenceTransformer(model_name, device=dev)
    def encode_query(self, text: str) -> np.ndarray:
        emb = self.model.encode([f"query: {text}"], normalize_embeddings=True,
                                batch_size=32, show_progress_bar=False)
        return np.asarray(emb[0], dtype=np.float32)

def get_collection():
    client = chromadb.PersistentClient(path=PERSIST_DIR)
    try:
        col = client.get_collection(COLLECTION_NAME)
    except Exception as e:
        names = [c.name for c in client.list_collections()]
        raise RuntimeError(f"æ‰¾ä¸åˆ° collection='{COLLECTION_NAME}'ï¼Œç›®å‰æœ‰ï¼š{names}") from e
    return col

# ========= å–®ç­†æ¨è«– â†’ å–æ ¸å¿ƒç‰¹å¾µ =========
def infer_core_feat(text: str, y_true: str, embedder: E5Embedder, collection, topk=5, temperature=0.7) -> CoreFeat:
    q = embedder.encode_query(text)
    res = collection.query(
        query_embeddings=[q.tolist()],
        n_results=topk,
        include=["metadatas", "documents", "distances", "embeddings"]
    )
    md = res.get("metadatas", [[]])[0]
    dists = res.get("distances", [[]])[0]
    embs = res.get("embeddings", [[]])[0]

    # sims
    if dists:
        d = np.array(dists, dtype=float)
        if np.all((0 <= d) & (d <= 2)):
            sims = 1.0 - d
        else:
            sims = -d
    elif embs:
        neigh = np.array(embs, dtype=np.float32)
        sims = neigh @ q
    else:
        raise RuntimeError("Chroma å›å‚³ç¼ºå°‘ distances/embeddingsã€‚")

    from collections import defaultdict
    votes = defaultdict(float)
    label_max_sim = defaultdict(lambda: -1e9)
    for i, m in enumerate(md):
        lb = m.get("label", "Other")
        s = float(sims[i])
        votes[lb] += s
        if s > label_max_sim[lb]:
            label_max_sim[lb] = s

    # é¡åˆ¥å…ˆé©—
    for lb in list(votes.keys()):
        votes[lb] *= float(CLASS_PRIOR.get(lb, 1.0))
    # è¦å‰‡å¾®åŠ æ¬Š
    if text and RULES:
        for lb, terms in RULES.items():
            if any(t in text for t in terms):
                votes[lb] += RULE_BONUS

    if not votes:
        return CoreFeat(text, y_true, "Other", 0.0, 0.0, 1.0)

    sorted_votes = sorted(votes.items(), key=lambda x: -x[1])
    lab1, sc1 = sorted_votes[0]
    lab2, sc2 = (sorted_votes[1] if len(sorted_votes) > 1 else ("<None>", 0.0))
    margin = float(sc1 - sc2)
    max_sim = float(label_max_sim[lab1])
    p = softmax_dict(votes, T=temperature)
    p1 = float(p.get(lab1, 0.0))
    return CoreFeat(text, y_true, lab1, max_sim, margin, p1)

# ========= ç”¨é–€æª»åšæ±ºç­– =========
def decide_label(cf: CoreFeat, decision: str, thr_sim: float, thr_margin: float, prob_thr: float) -> str:
    # sim_marginï¼šmax_sim>=thr_sim ä¸” margin>=thr_margin
    if decision == "sim_margin":
        return cf.top1 if (cf.max_sim >= thr_sim and cf.margin >= thr_margin) else "Other"
    elif decision == "prob":
        return cf.top1 if (cf.p1 >= prob_thr) else "Other"
    else:  # mixed
        ok1 = (cf.max_sim >= thr_sim and cf.margin >= thr_margin)
        ok2 = (cf.p1 >= prob_thr)
        return cf.top1 if (ok1 and ok2) else "Other"

def eval_preds(y_true: List[str], y_pred: List[str]) -> Tuple[float, float, str]:
    labels_set = sorted(list(set(y_true)))  # åƒ…ä»¥çœŸå¯¦å‡ºç¾çš„é¡åˆ¥è¨ˆ macro-F1
    f1 = f1_score(y_true, y_pred, average="macro", labels=labels_set, zero_division=0)
    acc = accuracy_score(y_true, y_pred)
    report = classification_report(y_true, y_pred, digits=4, zero_division=0)
    return f1, acc, report

# ========= è§£æ best_global.txt =========
def read_best_global(path: Path):
    txt = path.read_text(encoding="utf-8")
    m1 = re.search(r"thr_sim\s*=\s*([0-9.]+)", txt)
    m2 = re.search(r"thr_margin\s*=\s*([0-9.]+)", txt)
    if not (m1 and m2):
        raise ValueError("best_global.txt æ ¼å¼ç„¡æ³•è§£æ thr_sim/thr_margin")
    return float(m1.group(1)), float(m2.group(1))

# ========= ä¸»ç¨‹å¼ =========
def main():
    ap = argparse.ArgumentParser(description="æƒæ E5+Chroma çš„æ±ºç­–é–€æª»ï¼ˆå…¨åŸŸèˆ‡æ¯é¡åˆ¥å¾®èª¿ï¼‰")
    ap.add_argument("--csv", required=True, help="é©—è­‰é›† CSVï¼ˆtext,labelï¼‰")
    ap.add_argument("--decision", type=str, default="sim_margin", choices=["sim_margin","prob","mixed"])
    ap.add_argument("--topk", type=int, default=5)
    ap.add_argument("--temperature", type=float, default=0.7)
    ap.add_argument("--prob-thr", type=float, default=0.3, help="decision=prob/mixed æ™‚çš„æ©Ÿç‡é–€æª»")

    # å…¨åŸŸé–€æª»æƒæç¯„åœ
    ap.add_argument("--thr-sim-min", type=float, default=0.30)
    ap.add_argument("--thr-sim-max", type=float, default=0.45)
    ap.add_argument("--thr-sim-steps", type=int, default=16)
    ap.add_argument("--thr-margin-min", type=float, default=0.05)
    ap.add_argument("--thr-margin-max", type=float, default=0.15)
    ap.add_argument("--thr-margin-steps", type=int, default=11)

    # é‡ç”¨/è¼¸å…¥
    ap.add_argument("--load-features", type=str, default=None, help="å¦‚æœå·²ç¶“ç®—é features.parquetï¼Œå¯ç”¨é€™å€‹ç›´æ¥è¼‰å…¥çœæ™‚é–“")
    ap.add_argument("--use-global-from", type=str, default=None, help="è®€ best_global.txtï¼ˆå« thr_sim/thr_marginï¼‰ï¼Œè·³éå…¨åŸŸæƒæ")

    # æ¯é¡åˆ¥å¾®èª¿
    ap.add_argument("--tune-per-class", type=str, default=None, choices=[None,"sim","margin"], help="é¸æ“‡å¾®èª¿å“ªå€‹é–€æª»ï¼ˆsim æˆ– marginï¼‰")
    ap.add_argument("--per-class-steps", type=int, default=8, help="å–®é¡åˆ¥æƒææ­¥æ•¸ï¼ˆåœ¨å…¨åŸŸ thr é™„è¿‘åšå¾®èª¿ï¼‰")
    ap.add_argument("--per-class-span", type=float, default=0.06, help="å–®é¡åˆ¥æƒæç¯„åœå¯¬åº¦ï¼ˆÂ±span/2ï¼‰")

    # å…¶ä»–
    ap.add_argument("--model", type=str, default=EMBED_MODEL)
    ap.add_argument("--device", type=str, default="auto", choices=["auto","cpu","mps","cuda"])
    ap.add_argument("--out-dir", type=str, default="out_sweep")

    args = ap.parse_args()
    out_dir = Path(args.out_dir); out_dir.mkdir(parents=True, exist_ok=True)

    # è®€è³‡æ–™
    df = pd.read_csv(args.csv, encoding="utf-8-sig")
    if not {"text","label"}.issubset({c.strip().lower() for c in df.columns}):
        raise SystemExit("CSV å¿…é ˆåŒ…å« text,label æ¬„ä½")
    df = df.rename(columns={c:c.strip().lower() for c in df.columns})
    df["text"] = df["text"].astype(str).str.strip()
    df["label"] = df["label"].astype(str).str.strip()

    # è¼‰å…¥æˆ–è¨ˆç®— featuresï¼ˆæ¯ç­†çš„ top1,max_sim,margin,p1ï¼‰
    if args.load_features and Path(args.load_features).exists():
        feats = pd.read_parquet(args.load_features)
        print(f"âœ… å·²è¼‰å…¥ featuresï¼š{len(feats)} ç­†ï¼Œä¾†è‡ª {args.load_features}")
    else:
        embedder = E5Embedder(model_name=args.model, device=args.device)
        col = get_collection()
        feats_list: List[CoreFeat] = []
        for i, row in df.iterrows():
            cf = infer_core_feat(row["text"], row["label"], embedder, col,
                                 topk=args.topk, temperature=args.temperature)
            feats_list.append(cf)
            if (i+1) % 50 == 0:
                print(f"â€¦ å·²è™•ç† {i+1}/{len(df)}")
        feats = pd.DataFrame([cf.__dict__ for cf in feats_list])
        feats.to_parquet(out_dir / "features.parquet")
        print(f"ğŸ’¾ å·²å­˜ features åˆ° {out_dir/'features.parquet'}")

    y_true = feats["y_true"].tolist()

    # ---- å…¨åŸŸé–€æª» ----
    if args.use_global_from:
        thr_sim, thr_margin = read_best_global(Path(args.use_global_from))
        print(f"ğŸ” ä½¿ç”¨æ—¢æœ‰å…¨åŸŸé–€æª»ï¼šthr_sim={thr_sim:.4f} thr_margin={thr_margin:.4f}")
        # ç›´æ¥è©•ä¼°ä¸€æ¬¡
        y_pred = [decide_label(
                    CoreFeat(t, y, tp, ms, mg, p1),
                    args.decision, thr_sim, thr_margin, args.prob_thr
                  )
                  for t,y,tp,ms,mg,p1 in feats[["text","y_true","top1","max_sim","margin","p1"]].itertuples(index=False)]
        f1, acc, report = eval_preds(y_true, y_pred)
        (out_dir / "pred_global.csv").write_text(
            pd.DataFrame({"text":feats["text"],"true":y_true,"top1":feats["top1"],"pred":y_pred,
                          "max_sim":feats["max_sim"],"margin":feats["margin"],"p1":feats["p1"]}).to_csv(index=False),
            encoding="utf-8"
        )
        (out_dir / "best_global.txt").write_text(
            f"decision={args.decision}\nthr_sim={thr_sim:.6f}\nthr_margin={thr_margin:.6f}\n"
            f"macroF1={f1:.6f}\naccuracy={acc:.6f}\n\n{report}",
            encoding="utf-8"
        )
        print(f"â­ Macro-F1={f1:.4f}  Acc={acc:.4f}")
    else:
        sim_grid = np.linspace(args.thr_sim_min, args.thr_sim_max, args.thr_sim_steps)
        mar_grid = np.linspace(args.thr_margin_min, args.thr_margin_max, args.thr_margin_steps)
        best = (-1.0, None, None, None, None)  # f1, acc, thr_sim, thr_margin, y_pred
        for ts in sim_grid:
            for tm in mar_grid:
                y_pred = [decide_label(
                            CoreFeat(t, y, tp, ms, mg, p1),
                            args.decision, ts, tm, args.prob_thr
                          )
                          for t,y,tp,ms,mg,p1 in feats[["text","y_true","top1","max_sim","margin","p1"]].itertuples(index=False)]
                f1, acc, _ = eval_preds(y_true, y_pred)
                if f1 > best[0]:
                    best = (f1, acc, ts, tm, y_pred)
        f1, acc, thr_sim, thr_margin, y_pred = best
        print(f"ğŸŒŸ å…¨åŸŸæœ€ä½³ï¼šMacro-F1={f1:.4f} Acc={acc:.4f}  thr_sim={thr_sim:.4f} thr_margin={thr_margin:.4f}")
        report = classification_report(y_true, y_pred, digits=4, zero_division=0)
        pd.DataFrame({"text":feats["text"],"true":y_true,"top1":feats["top1"],"pred":y_pred,
                      "max_sim":feats["max_sim"],"margin":feats["margin"],"p1":feats["p1"]}).to_csv(out_dir/"pred_global.csv", index=False, encoding="utf-8")
        (out_dir / "best_global.txt").write_text(
            f"decision={args.decision}\nthr_sim={thr_sim:.6f}\nthr_margin={thr_margin:.6f}\n"
            f"macroF1={f1:.6f}\naccuracy={acc:.6f}\n\n{report}",
            encoding="utf-8"
        )

    # ---- æ¯é¡åˆ¥å¾®èª¿ï¼ˆå¯é¸ï¼‰ ----
    if args.tune_per_class:
        base_thr_sim, base_thr_margin = read_best_global(out_dir / "best_global.txt")
        labels = sorted(set(y_true))
        per_thr = {lb: {"sim": base_thr_sim, "margin": base_thr_margin} for lb in labels}

        for lb in labels:
            mask = (feats["top1"] == lb)
            if not mask.any():
                continue
            vals = feats.loc[mask, "max_sim" if args.tune_per_class=="sim" else "margin"].values
            if len(vals) == 0:
                continue
            lo = np.percentile(vals, 20)
            hi = np.percentile(vals, 80)
            span = args.per_class_span
            center = (lo + hi) / 2.0
            cand = np.linspace(center - span/2, center + span/2, args.per_class_steps)
            cand = np.clip(cand, 0, 1)
            best_f1, best_val = -1.0, None
            for v in cand:
                # æ‡‰ç”¨ per-class é–€æª»ï¼šåªæœ‰ top1==lb çš„æ¨£æœ¬ç”¨æ–°å€¼ï¼Œå…¶é¤˜ç”¨ base
                y_pred = []
                for t,y,tp,ms,mg,p1 in feats[["text","y_true","top1","max_sim","margin","p1"]].itertuples(index=False):
                    ts = per_thr[tp]["sim"]
                    tm = per_thr[tp]["margin"]
                    if tp == lb:
                        if args.tune_per_class == "sim":
                            ts = float(v)
                        else:
                            tm = float(v)
                    y_pred.append(decide_label(CoreFeat(t,y,tp,ms,mg,p1), args.decision, ts, tm, args.prob_thr))
                f1, _, _ = eval_preds(y_true, y_pred)
                if f1 > best_f1:
                    best_f1, best_val = f1, float(v)
            if best_val is not None:
                per_thr[lb][args.tune_per_class] = best_val
                print(f"ğŸ§© é¡åˆ¥ã€Œ{lb}ã€æœ€ä½³ {args.tune_per_class} = {best_val:.4f}  (Macro-F1={best_f1:.4f})")

        # æœ€çµ‚ç”¨ per_thr è©•ä¼°
        def decide_with_per_thr(cf: CoreFeat) -> str:
            ts = per_thr.get(cf.top1, {}).get("sim", base_thr_sim)
            tm = per_thr.get(cf.top1, {}).get("margin", base_thr_margin)
            return decide_label(cf, args.decision, ts, tm, args.prob_thr)

        y_pred = [decide_with_per_thr(CoreFeat(t,y,tp,ms,mg,p1))
                  for t,y,tp,ms,mg,p1 in feats[["text","y_true","top1","max_sim","margin","p1"]].itertuples(index=False)]
        f1, acc, report = eval_preds(y_true, y_pred)

        # è¼¸å‡º
        with open(out_dir/"per_class_thr.json", "w", encoding="utf-8") as f:
            json.dump(per_thr, f, ensure_ascii=False, indent=2)
        pd.DataFrame({"text":feats["text"],"true":y_true,"top1":feats["top1"],"pred":y_pred,
                      "max_sim":feats["max_sim"],"margin":feats["margin"],"p1":feats["p1"]}).to_csv(out_dir/"pred_per_class.csv", index=False, encoding="utf-8")
        (out_dir / "best_per_class.txt").write_text(
            f"decision={args.decision}\nmacroF1={f1:.6f}\naccuracy={acc:.6f}\n\n{report}",
            encoding="utf-8"
        )
        print(f"ğŸ¯ æ¯é¡åˆ¥å¾®èª¿å®Œæˆï¼šMacro-F1={f1:.4f}  Acc={acc:.4f}\nâ†’ per_class_thr.json å·²ç”¢ç”Ÿæ–¼ {out_dir}")
    else:
        print("ï¼ˆç•¥éæ¯é¡åˆ¥å¾®èª¿ï¼›è‹¥éœ€è¦è«‹åŠ  --tune-per-class sim æˆ– --tune-per-class marginï¼‰")

if __name__ == "__main__":
    main()
